{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install noisereduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAIC-WOZ 음성 데이터 전처리 \n",
    "- Participant 음성만 남김\n",
    "- 잡음 제거\n",
    "- 1분 이내로 끊음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_audio(start_id, end_id, directory):\n",
    "\n",
    "    for file_id in range(start_id, end_id + 1):\n",
    "        audio_path = f\"{directory}/{file_id}_AUDIO.wav\"\n",
    "        transcript_path = f\"{directory}/{file_id}_TRANSCRIPT.csv\"\n",
    "\n",
    "        try:\n",
    "        \n",
    "            # TRANSCRIPT.csv 파일에서 Participant 의 대사만 추출\n",
    "            transcript = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "            participant_transcript = transcript[transcript['speaker'] == 'Participant']\n",
    "            \n",
    "            # 오디오 파일 로드\n",
    "            audio = AudioSegment.from_wav(audio_path)\n",
    "            \n",
    "            # 최종 오디오를 생성할 리스트\n",
    "            final_audio = AudioSegment.silent(duration=0)\n",
    "            \n",
    "            # 라벨 \n",
    "            n = 1\n",
    "\n",
    "            # 대사별 오디오 처리 및 결합\n",
    "            for index, row in participant_transcript.iterrows():\n",
    "                start_time = int(row['start_time'] * 1000)  # 시작 시간을 밀리세컨드로 변환\n",
    "                end_time = int(row['stop_time'] * 1000)  # 종료 시간을 밀리세컨드로 변환\n",
    "                \n",
    "                # 잘라낸 오디오\n",
    "                segment = audio[start_time:end_time]\n",
    "                \n",
    "                # 잡음 제거\n",
    "                segment_np = np.array(segment.get_array_of_samples())\n",
    "                reduced_noise = nr.reduce_noise(y=segment_np, sr=segment.frame_rate)\n",
    "                \n",
    "                # pydub 오디오로 변환\n",
    "                clean_segment = AudioSegment(\n",
    "                    data=reduced_noise.tobytes(),\n",
    "                    sample_width=segment.sample_width,\n",
    "                    frame_rate=segment.frame_rate,\n",
    "                    channels=segment.channels\n",
    "                )\n",
    "                \n",
    "                # 결합 전 길이 확인 및 파일 분할\n",
    "                if len(final_audio) + len(clean_segment) > 60000:  # 1분 초과 시 새 파일 시작\n",
    "                    final_audio.export(f\"../data/reduce/{file_id}_processed_{n}.wav\", format=\"wav\")\n",
    "                    final_audio = clean_segment\n",
    "                    n += 1\n",
    "                else:\n",
    "                    final_audio += clean_segment\n",
    "            \n",
    "            # 마지막 파일 저장\n",
    "            if len(final_audio) > 0:\n",
    "                final_audio.export(f\"../data/reduce/{file_id}_processed_final.wav\", format=\"wav\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_id}: {e}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:71: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\base.py:224: RuntimeWarning: invalid value encountered in cast\n",
      "  return filtered_chunk.astype(self._dtype).flatten()\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:71: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\base.py:224: RuntimeWarning: invalid value encountered in cast\n",
      "  return filtered_chunk.astype(self._dtype).flatten()\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\nonstationary.py:71: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\noisereduce\\spectralgate\\base.py:224: RuntimeWarning: invalid value encountered in cast\n",
      "  return filtered_chunk.astype(self._dtype).flatten()\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "process_audio(300, 492, '../data/out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 분할 저장\n",
    "train,dev,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_splits(directory):\n",
    "    # 분할 정보 로드\n",
    "    dev = pd.read_csv(f\"{directory}/dev_split_Depression.csv\")\n",
    "    test = pd.read_csv(f\"{directory}/full_test_split.csv\")\n",
    "    train = pd.read_csv(f\"{directory}/train_split_Depression.csv\")\n",
    "\n",
    "    # 분할을 딕셔너리로 구성\n",
    "    splits = {}\n",
    "    splits.update(dict.fromkeys(dev['Participant_ID'], 'dev'))\n",
    "    splits.update(dict.fromkeys(test['Participant_ID'], 'test'))\n",
    "    splits.update(dict.fromkeys(train['Participant_ID'], 'train'))\n",
    "    return splits\n",
    "\n",
    "def process_audio(start_id, end_id, directory, splits):\n",
    "    for file_id in range(start_id, end_id + 1):\n",
    "        audio_path = f\"{directory}/{file_id}_AUDIO.wav\"\n",
    "        transcript_path = f\"{directory}/{file_id}_TRANSCRIPT.csv\"\n",
    "\n",
    "        try:\n",
    "            # TRANSCRIPT.csv 파일에서 Participant 의 대사만 추출\n",
    "            transcript = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "            participant_transcript = transcript[transcript['speaker'] == 'Participant']\n",
    "\n",
    "            # 오디오 파일 로드\n",
    "            audio = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "            # 최종 오디오를 생성할 리스트\n",
    "            final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "            # 라벨 초기화\n",
    "            n = 1\n",
    "            split_folder = splits.get(file_id, 'unknown')\n",
    "\n",
    "            # 대사별 오디오 처리 및 결합\n",
    "            for index, row in participant_transcript.iterrows():\n",
    "                start_time = int(row['start_time'] * 1000)  # 시작 시간을 밀리세컨드로 변환\n",
    "                end_time = int(row['stop_time'] * 1000)  # 종료 시간을 밀리세컨드로 변환\n",
    "                \n",
    "                # 잘라낸 오디오\n",
    "                segment = audio[start_time:end_time]\n",
    "                \n",
    "                # 잡음 제거\n",
    "                segment_np = np.array(segment.get_array_of_samples())\n",
    "                reduced_noise = nr.reduce_noise(y=segment_np, sr=segment.frame_rate)\n",
    "                \n",
    "                # pydub 오디오로 변환\n",
    "                clean_segment = AudioSegment(\n",
    "                    data=reduced_noise.tobytes(),\n",
    "                    sample_width=segment.sample_width,\n",
    "                    frame_rate=segment.frame_rate,\n",
    "                    channels=segment.channels\n",
    "                )\n",
    "                \n",
    "                # 결합 전 길이 확인 및 파일 분할\n",
    "                if len(final_audio) + len(clean_segment) > 60000:  # 1분 초과 시 새 파일 시작\n",
    "                    final_audio.export(f\"../data/reduce/{split_folder}/{file_id}_processed_{n}.wav\", format=\"wav\")\n",
    "                    final_audio = clean_segment\n",
    "                    n += 1\n",
    "                else:\n",
    "                    final_audio += clean_segment\n",
    "            \n",
    "            # 마지막 파일 저장\n",
    "            if len(final_audio) > 0:\n",
    "                final_audio.export(f\"../data/reduce/{split_folder}/{file_id}_processed_final.wav\", format=\"wav\")\n",
    "                print(f\"{file_id}_final 저장완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 분할 정보 로드\n",
    "splits = load_splits('../split')\n",
    "\n",
    "# 함수 실행\n",
    "process_audio(300, 492, '../data/out', splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### librosa로 잡음 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_noise_librosa(audio_segment):\n",
    "    # Pydub 오디오를 Numpy 배열로 변환\n",
    "    audio_np = np.array(audio_segment.get_array_of_samples())\n",
    "    sr = audio_segment.frame_rate\n",
    "\n",
    "    # Librosa를 이용해 오디오 파일 읽기\n",
    "    y = np.float32(audio_np) / 2**15\n",
    "\n",
    "    # 잡음이 있다고 판단되는 부분을 찾아 잡음 프로필을 생성\n",
    "    noise_part = y[:int(sr*0.5)]  # 예를 들어, 처음 0.5초간의 오디오를 잡음으로 가정\n",
    "    noise_profile = np.mean(librosa.feature.mfcc(y=noise_part, sr=sr, n_mfcc=20), axis=1)\n",
    "    noise = np.tile(noise_profile, (len(y) // len(noise_profile), 1)).flatten()[:len(y)]\n",
    "\n",
    "    # 원 오디오에서 잡음 프로필을 제거\n",
    "    y_reduced = y - noise\n",
    "\n",
    "    # 결과를 다시 Pydub 오디오로 변환\n",
    "    reduced_np = np.int16(y_reduced * 2**15)\n",
    "    clean_segment = AudioSegment(\n",
    "        data=reduced_np.tobytes(),\n",
    "        sample_width=audio_segment.sample_width,\n",
    "        frame_rate=sr,\n",
    "        channels=audio_segment.channels\n",
    "    )\n",
    "    \n",
    "    return clean_segment\n",
    "\n",
    "def process_audio(start_id, end_id, directory):\n",
    "    for file_id in range(start_id, end_id + 1):\n",
    "        audio_path = f\"{directory}/{file_id}_AUDIO.wav\"\n",
    "        transcript_path = f\"{directory}/{file_id}_TRANSCRIPT.csv\"\n",
    "        \n",
    "        try:\n",
    "            # TRANSCRIPT.csv 파일에서 Participant 의 대사만 추출\n",
    "            transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "            participant_transcript = transcript[transcript['speaker'] == 'Participant']\n",
    "            \n",
    "            # 오디오 파일 로드\n",
    "            audio = AudioSegment.from_wav(audio_path)\n",
    "            \n",
    "            # 최종 오디오를 생성할 리스트\n",
    "            final_audio = AudioSegment.silent(duration=0)\n",
    "            \n",
    "            # 라벨링\n",
    "            n = 1\n",
    "\n",
    "            # 대사별 오디오 처리 및 결합\n",
    "            for index, row in participant_transcript.iterrows():\n",
    "                start_time = int(row['start_time'] * 1000)\n",
    "                stop_time = int(row['stop_time'] * 1000)\n",
    "                \n",
    "                # 잘라낸 오디오\n",
    "                segment = audio[start_time:stop_time]\n",
    "                \n",
    "                # 잡음 제거\n",
    "                clean_segment = reduce_noise_librosa(segment)\n",
    "                \n",
    "                # 결합 전 길이 확인 및 파일 분할\n",
    "                if len(final_audio) + len(clean_segment) > 60000:\n",
    "                    final_audio.export(f\"../data/librosa/{file_id}_processed_{n}.wav\", format=\"wav\")\n",
    "                    final_audio = clean_segment\n",
    "                    n += 1\n",
    "                else:\n",
    "                    final_audio += clean_segment\n",
    "            \n",
    "            # 마지막 파일 저장\n",
    "            if len(final_audio) > 0:\n",
    "                final_audio.export(f\"../data/librosa/{file_id}_processed_final.wav\", format=\"wav\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file 301: operands could not be broadcast together with shapes (19856,) (19840,) \n",
      "Error processing file 302: operands could not be broadcast together with shapes (45328,) (45320,) \n",
      "Error processing file 303: operands could not be broadcast together with shapes (15056,) (15040,) \n",
      "Error processing file 304: operands could not be broadcast together with shapes (7024,) (7020,) \n",
      "Error processing file 305: operands could not be broadcast together with shapes (240784,) (240780,) \n",
      "Error processing file 306: operands could not be broadcast together with shapes (185584,) (185580,) \n",
      "Error processing file 307: operands could not be broadcast together with shapes (193632,) (193620,) \n",
      "Error processing file 308: operands could not be broadcast together with shapes (9776,) (9760,) \n",
      "Error processing file 309: operands could not be broadcast together with shapes (21616,) (21600,) \n",
      "Error processing file 310: operands could not be broadcast together with shapes (4944,) (4940,) \n",
      "Error processing file 311: operands could not be broadcast together with shapes (20144,) (20140,) \n",
      "Error processing file 312: operands could not be broadcast together with shapes (38704,) (38700,) \n",
      "Error processing file 313: operands could not be broadcast together with shapes (6416,) (6400,) \n",
      "Error processing file 314: operands could not be broadcast together with shapes (86432,) (86420,) \n",
      "Error processing file 315: operands could not be broadcast together with shapes (182208,) (182200,) \n",
      "Error processing file 316: operands could not be broadcast together with shapes (8496,) (8480,) \n",
      "Error processing file 317: operands could not be broadcast together with shapes (75488,) (75480,) \n",
      "Error processing file 318: operands could not be broadcast together with shapes (34544,) (34540,) \n",
      "Error processing file 319: operands could not be broadcast together with shapes (15696,) (15680,) \n",
      "Error processing file 320: operands could not be broadcast together with shapes (20784,) (20780,) \n",
      "Error processing file 321: operands could not be broadcast together with shapes (86304,) (86300,) \n",
      "Error processing file 322: operands could not be broadcast together with shapes (126576,) (126560,) \n",
      "Error processing file 323: operands could not be broadcast together with shapes (21744,) (21740,) \n",
      "Error processing file 324: operands could not be broadcast together with shapes (30096,) (30080,) \n",
      "Error processing file 325: operands could not be broadcast together with shapes (46656,) (46640,) \n",
      "Error processing file 327: operands could not be broadcast together with shapes (27536,) (27520,) \n",
      "Error processing file 329: operands could not be broadcast together with shapes (42752,) (42740,) \n",
      "Error processing file 330: operands could not be broadcast together with shapes (30544,) (30540,) \n",
      "Error processing file 331: operands could not be broadcast together with shapes (153584,) (153580,) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 예제 사용 방법\n",
    "process_audio(300, 492, '../data/out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
