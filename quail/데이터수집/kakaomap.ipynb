{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### url 가져오기\n",
    "\n",
    "## 카카오 맵 \n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://map.kakao.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "## input 창에 검색어 입력\n",
    "searchbox = driver.find_element(By.ID, 'search.keyword.query')\n",
    "searchbox.send_keys('홍대 맛집'+ Keys.ENTER)\n",
    "time.sleep(3)\n",
    "\n",
    "## 상세보기 주소 가져오기 \n",
    "list_url = []\n",
    "\n",
    "## 아래 1,2,3,4,5 리스트 번호 다 뜨도록\n",
    "# 장소 더보기 클릭\n",
    "driver.find_element(By.ID, 'info.search.place.more').click()\n",
    "time.sleep(2)\n",
    "# 1번리스트로 돌아오기\n",
    "driver.find_element(By.ID, 'info.search.page.no1').click()\n",
    "time.sleep(2)\n",
    "\n",
    "for count in range(1):\n",
    "    \n",
    "    for inx in range(2, 6):\n",
    "        \n",
    "        # 현재 리스트의 상세보기 주소 스크래핑\n",
    "        moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "        for i in range(len(moreview_element)):\n",
    "            list_url.append(moreview_element[i].get_attribute('href'))\n",
    "        # 다음 리스트 클릭\n",
    "        driver.find_element(By.ID, f'info.search.page.no{inx}').click()\n",
    "        # 5번 리스트 저장\n",
    "        if inx == 5:\n",
    "            moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "            for i in range(len(moreview_element)):\n",
    "                list_url.append(moreview_element[i].get_attribute('href'))\n",
    "        time.sleep(2)\n",
    "    # 다음 리스트 페이지 넘어가기\n",
    "    driver.find_element(By.ID ,'info.search.page.next').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "## 웹페이지 종료\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정보 넣을 빈 딕셔너리\n",
    "data = {\n",
    "    'merchant' : [],\n",
    "    'category' : [],\n",
    "    'star' : [],\n",
    "    'address' : [],\n",
    "    'oper_time' : [],\n",
    "    'starCount' : [],\n",
    "    'reviewCount' : []\n",
    "}\n",
    "\n",
    "### 기본 정보 크롤링 (상세보기 get으로 열어서 가져오기)\n",
    "driver = webdriver.Chrome()\n",
    "for i in range(len(list_url)):\n",
    "\n",
    "    data2 = {\n",
    "    'user_name' : [],\n",
    "    'user_rank' : [],\n",
    "    'num_response' : [],\n",
    "    'user_star' : [], \n",
    "    'time' : [],\n",
    "    'rating' : [],\n",
    "    'content' : []\n",
    "    }\n",
    "\n",
    "    ## 상세보기 웹페이지 열기\n",
    "    driver.get(list_url[i])\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 영업시간 더 보기 클릭\n",
    "    try:\n",
    "        oper_more = driver.find_elements(By.CSS_SELECTOR, 'a[data-logevent = \"main_info,more_timeinfo\"]')\n",
    "        oper_more[0].click()\n",
    "        time.sleep(2)  \n",
    "\n",
    "    # 영업시간 더보기가 없는 경우\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 후기 더보기 클릭\n",
    "    try:\n",
    "        link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "        while link_more.text == \"후기 더보기\":\n",
    "            link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "            # 마지막 후기 더보기까지 눌렀으면 멈추기\n",
    "            if link_more.text != \"후기 접기\":\n",
    "                link_more.click()\n",
    "                time.sleep(0.3)\n",
    "    # 후기 더보기 없는 경우        \n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(0.1)\n",
    "  \n",
    "    ## 상세page bs4 파싱 분석\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        ##canvas 이미지 저장\n",
    "\n",
    "        test_image = driver.execute_script(\"return document.querySelectorAll('canvas')[1].toDataURL();\")\n",
    "        image_data = test_image.split(',')[1]\n",
    "\n",
    "        ## Base64 디코딩하여 이미지 데이터 추출\n",
    "        image_data_decoded = base64.b64decode(image_data)\n",
    "\n",
    "        test_image2 = driver.execute_script(\"return document.querySelectorAll('canvas')[2].toDataURL();\")\n",
    "        image_data2 = test_image2.split(',')[1]\n",
    "\n",
    "        ## Base64 디코딩하여 이미지 데이터 추출\n",
    "        image_data_decoded2 = base64.b64decode(image_data2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    ## 매장명\n",
    "    mer = soup.find('h2', {'class':'tit_location'}).get_text()\n",
    "    data['merchant'].append(mer)\n",
    "    ## 분류\n",
    "    data['category'].append(soup.find('span',{'class':'txt_location'}).get_text().split(':')[1].strip())\n",
    "    ## 주소\n",
    "    data['address'].append(soup.find('span', {'class': 'txt_address'}).get_text().replace(\" \", \"\").replace(\"\\n\", \" \"))\n",
    "\n",
    "    ## 별점, 리뷰 수 \n",
    "    # 별점 있는 경우\n",
    "    if len(soup.find_all('span',{'class':'color_b'})) > 1:\n",
    "        data['star'].append(soup.find_all('span', {'class':'color_b'})[0].get_text().strip('점'))\n",
    "        data['starCount'].append(soup.find('a', {'class': 'link_evaluation'})['data-cnt'])\n",
    "        data['reviewCount'].append(soup.find_all('span', {'class':'color_b'})[1].get_text().strip('개'))\n",
    "    # 별점 없는 경우\n",
    "    else:\n",
    "        data['star'].append('0')\n",
    "        data['starCount'].append('0')\n",
    "        data['reviewCount'].append(soup.find('span', {'class':'color_b'}).get_text().strip('개'))\n",
    "\n",
    "    ## 영업시간\n",
    "    # 더보기 있는 경우\n",
    "    if oper_more:    \n",
    "        data['oper_time'].append(soup.find_all('ul', {'class':'list_operation'})[1].get_text().strip())\n",
    "    # 더보기 없는 경우\n",
    "    else:\n",
    "        data['oper_time'].append(soup.find('ul', {'class':'list_operation'}).get_text().strip().replace(\"\\n\", \"\"))\n",
    "\n",
    "\n",
    "    # 리뷰 목록 잡기\n",
    "    reveiw_listed = soup.find_all('li', {'data-ismy':'false'})\n",
    "\n",
    "    #### df2 만들기 (리뷰df)\n",
    "    for j in range(len(reveiw_listed)):\n",
    "        ## 유저 이름\n",
    "        data2['user_name'].append(soup.find_all('span',{'class':'txt_username'})[j].get_text())\n",
    "        ## 유저 레벨\n",
    "        data2['user_rank'].append(soup.find_all('span', {'class' : 'txt_badge'})[j].get_text().strip('레벨'))\n",
    "        ## 유저 후기수\n",
    "        data2['num_response'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[0].get_text()\n",
    "        )\n",
    "        ## 유저 별점 평균\n",
    "        data2['user_star'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[1].get_text()\n",
    "        )\n",
    "        ### 리뷰 작성 시간\n",
    "        data2['time'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find('span',{'class':'time_write'}).get_text()\n",
    "        )\n",
    "        ## 리뷰 내용\n",
    "        data2['content'].append(\n",
    "            soup.find_all('p', {'class':'txt_comment'})[j].get_text().strip('더보기')\n",
    "        )\n",
    "\n",
    "        ## 유저가 평가한 별점 \n",
    "        # 너비를 추출하여 별점 계산 (너비는 별점의 백분율을 나타냄)\n",
    "        style_attribute = soup.find_all('div', {'class':'star_info'})[j].find('span',{'class':'ico_star inner_star'})['style']\n",
    "        width_percent = float(style_attribute.split(':')[1].strip('%;'))\n",
    "        rating_out_of_five = width_percent / 20  # 별점은 100%를 5로 나눈 값\n",
    "        data2['rating'].append(rating_out_of_five)\n",
    "\n",
    "    ## 데이터 프레임으로 만들기\n",
    "    df2 = pd.DataFrame(data2)\n",
    "    df2.to_csv(f'./data2/{mer}.csv',index = False)\n",
    "\n",
    "    try:\n",
    "        # 이미지 데이터를 파일로 저장\n",
    "        with open(f'./image/{mer}1.png', 'wb') as f:\n",
    "            f.write(image_data_decoded)\n",
    "\n",
    "        with open(f'./image/{mer}2.png', 'wb') as f:\n",
    "            f.write(image_data_decoded2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"{i+1}번째 데이터 입력 완료, {mer}.csv 저장 완료\")\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"./data1/data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
