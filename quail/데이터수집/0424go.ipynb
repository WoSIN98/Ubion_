{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./data2/피오니 홍대점.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_rank</th>\n",
       "      <th>num_response</th>\n",
       "      <th>user_star</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>라멘처돌이</td>\n",
       "      <td>54</td>\n",
       "      <td>374</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2024.04.17.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>예전에는 특별했는데 우유빙수가 흔해지면서부터  굳이 갈 이유가 사라짐 오히려 무스케...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>밍꾸</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024.04.15.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2월에 방문했습니다)10년전부터 유명한거 알고있었고,늘 사람많고 못가다가이번에 우...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>밥밥</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2024.04.07.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>딸케 맛있음 과하게 달지않고 크림도 안느끼하고 딱 맛잇엇어용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>불꽃휴먼</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024.03.29.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>맛이랑 분위기는 좋은데 비싸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banana lizard</td>\n",
       "      <td>25</td>\n",
       "      <td>79</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024.03.18.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>디저트는 그저 그렇고, 커피가 맛있어요!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>ak</td>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2017.01.15.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>나경</td>\n",
       "      <td>22</td>\n",
       "      <td>714</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2016.07.05.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>그리고</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2016.03.21.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>먹어본 딸기 케이크중 가장 맛있었음너무 달지않지도 느끼하지도 않음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>전주희</td>\n",
       "      <td>39</td>\n",
       "      <td>446</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2016.03.11.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>봄이라 더 맛있다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>정은</td>\n",
       "      <td>63</td>\n",
       "      <td>911</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2016.03.10.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>딸기 생크림케익/딸기 빙수</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name  user_rank num_response  user_star         time  rating  \\\n",
       "0            라멘처돌이         54          374        4.4  2024.04.17.     5.0   \n",
       "1               밍꾸          3            1        1.0  2024.04.15.     1.0   \n",
       "2               밥밥         16           34        4.1  2024.04.07.     5.0   \n",
       "3             불꽃휴먼         11           24        4.0  2024.03.29.     4.0   \n",
       "4    banana lizard         25           79        3.2  2024.03.18.     4.0   \n",
       "..             ...        ...          ...        ...          ...     ...   \n",
       "269             ak          5          158        3.9  2017.01.15.     5.0   \n",
       "270             나경         22          714        3.4  2016.07.05.     4.0   \n",
       "271            그리고         22           56        3.5  2016.03.21.     5.0   \n",
       "272            전주희         39          446        3.2  2016.03.11.     5.0   \n",
       "273             정은         63          911        3.6  2016.03.10.     5.0   \n",
       "\n",
       "                                               content  \n",
       "0    예전에는 특별했는데 우유빙수가 흔해지면서부터  굳이 갈 이유가 사라짐 오히려 무스케...  \n",
       "1    (2월에 방문했습니다)10년전부터 유명한거 알고있었고,늘 사람많고 못가다가이번에 우...  \n",
       "2                    딸케 맛있음 과하게 달지않고 크림도 안느끼하고 딱 맛잇엇어용  \n",
       "3                                      맛이랑 분위기는 좋은데 비싸  \n",
       "4                               디저트는 그저 그렇고, 커피가 맛있어요!  \n",
       "..                                                 ...  \n",
       "269                                                NaN  \n",
       "270                                                NaN  \n",
       "271               먹어본 딸기 케이크중 가장 맛있었음너무 달지않지도 느끼하지도 않음  \n",
       "272                                          봄이라 더 맛있다  \n",
       "273                                     딸기 생크림케익/딸기 빙수  \n",
       "\n",
       "[274 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### url 가져오기\n",
    "\n",
    "## 카카오 맵 \n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://map.kakao.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "## input 창에 검색어 입력\n",
    "searchbox = driver.find_element(By.ID, 'search.keyword.query')\n",
    "searchbox.send_keys('홍대 맛집'+ Keys.ENTER)\n",
    "time.sleep(3)\n",
    "\n",
    "## 상세보기 주소 가져오기 \n",
    "list_url = []\n",
    "\n",
    "## 아래 1,2,3,4,5 리스트 번호 다 뜨도록\n",
    "# 장소 더보기 클릭\n",
    "driver.find_element(By.ID, 'info.search.place.more').click()\n",
    "time.sleep(2)\n",
    "# 1번리스트로 돌아오기\n",
    "driver.find_element(By.ID, 'info.search.page.no1').click()\n",
    "time.sleep(2)\n",
    "\n",
    "for count in range(1):\n",
    "    \n",
    "    for inx in range(2, 6):\n",
    "        \n",
    "        # 현재 리스트의 상세보기 주소 스크래핑\n",
    "        moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "        for i in range(len(moreview_element)):\n",
    "            list_url.append(moreview_element[i].get_attribute('href'))\n",
    "        # 다음 리스트 클릭\n",
    "        driver.find_element(By.ID, f'info.search.page.no{inx}').click()\n",
    "        # 5번 리스트 저장\n",
    "        if inx == 5:\n",
    "            moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "            for i in range(len(moreview_element)):\n",
    "                list_url.append(moreview_element[i].get_attribute('href'))\n",
    "        time.sleep(2)\n",
    "    # 다음 리스트 페이지 넘어가기\n",
    "    driver.find_element(By.ID ,'info.search.page.next').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "## 웹페이지 종료\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "## 정보 넣을 빈 딕셔너리\n",
    "data = {\n",
    "    'merchant' : [],\n",
    "    'category' : [],\n",
    "    'star' : [],\n",
    "    'address' : [],\n",
    "    'oper_time' : [],\n",
    "    'starCount' : [],\n",
    "    'reviewCount' : []\n",
    "}\n",
    "data2 = {\n",
    "    'user_name' : [],\n",
    "    'user_rank' : [],\n",
    "    'num_response' : [],\n",
    "    'user_star' : [], \n",
    "    'time' : [],\n",
    "    'rating' : [],\n",
    "    'content' : []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "### 기본 정보 크롤링 (상세보기 get으로 열어서 가져오기)\n",
    "\n",
    "for i in range(len(list_url)):\n",
    "\n",
    "   \n",
    "    ## 상세보기 웹페이지 열기\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(list_url[i])\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 영업시간 더 보기 클릭\n",
    "    try:\n",
    "        oper_more = driver.find_elements(By.CSS_SELECTOR, 'a[data-logevent = \"main_info,more_timeinfo\"]')\n",
    "        oper_more[0].click()\n",
    "        time.sleep(2)  \n",
    "\n",
    "    # 영업시간 더보기가 없는 경우\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 후기 더보기 클릭\n",
    "    try:\n",
    "        link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "        while link_more.text == \"후기 더보기\":\n",
    "            link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "            # 마지막 후기 더보기까지 눌렀으면 멈추기\n",
    "            if link_more.text != \"후기 접기\":\n",
    "                link_more.click()\n",
    "                time.sleep(0.3)\n",
    "    # 후기 더보기 없는 경우        \n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(0.1)\n",
    "  \n",
    "    ## 상세page bs4 파싱 분석\n",
    "    soup = bs(driver.page_source, 'lxml')\n",
    "\n",
    "    ##canvas 이미지 저장\n",
    "\n",
    "    test_image = driver.execute_script(\"return document.querySelectorAll('canvas')[1].toDataURL();\")\n",
    "    image_data = test_image.split(',')[1]\n",
    "\n",
    "    ## Base64 디코딩하여 이미지 데이터 추출\n",
    "    image_data_decoded = base64.b64decode(image_data)\n",
    "\n",
    "    test_image2 = driver.execute_script(\"return document.querySelectorAll('canvas')[2].toDataURL();\")\n",
    "    image_data2 = test_image2.split(',')[1]\n",
    "\n",
    "    ## Base64 디코딩하여 이미지 데이터 추출\n",
    "    image_data_decoded2 = base64.b64decode(image_data2)\n",
    "\n",
    "\n",
    "        \n",
    "    # 웹페이지 닫기\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "\n",
    "    ## 매장명\n",
    "    mer = soup.find('h2', {'class':'tit_location'}).get_text()\n",
    "    data['merchant'].append(mer)\n",
    "    ## 분류\n",
    "    data['category'].append(soup.find('span',{'class':'txt_location'}).get_text().split(':')[1].strip())\n",
    "    ## 주소\n",
    "    data['address'].append(soup.find('span', {'class': 'txt_address'}).get_text().replace(\" \", \"\").replace(\"\\n\", \" \"))\n",
    "\n",
    "    ## 별점, 리뷰 수 \n",
    "    # 별점 있는 경우\n",
    "    if len(soup.find_all('span',{'class':'color_b'})) > 1:\n",
    "        data['star'].append(soup.find_all('span', {'class':'color_b'})[0].get_text().strip('점'))\n",
    "        data['starCount'].append(soup.find('a', {'class': 'link_evaluation'})['data-cnt'])\n",
    "        data['reviewCount'].append(soup.find_all('span', {'class':'color_b'})[1].get_text().strip('개'))\n",
    "    # 별점 없는 경우\n",
    "    else:\n",
    "        data['star'].append('0')\n",
    "        data['starCount'].append('0')\n",
    "        data['reviewCount'].append(soup.find('span', {'class':'color_b'}).get_text().strip('개'))\n",
    "\n",
    "    ## 영업시간\n",
    "    # 더보기 있는 경우\n",
    "    if oper_more:    \n",
    "        data['oper_time'].append(soup.find_all('ul', {'class':'list_operation'})[1].get_text().strip())\n",
    "    # 더보기 없는 경우\n",
    "    else:\n",
    "        data['oper_time'].append(soup.find('ul', {'class':'list_operation'}).get_text().strip().replace(\"\\n\", \"\"))\n",
    "\n",
    "\n",
    "    # 리뷰 목록 잡기\n",
    "    reveiw_listed = soup.find_all('li', {'data-ismy':'false'})\n",
    "\n",
    "    #### df2 만들기 (리뷰df)\n",
    "    for j in range(len(reveiw_listed)):\n",
    "        ## 유저 이름\n",
    "        data2['user_name'].append(soup.find_all('span',{'class':'txt_username'})[j].get_text())\n",
    "        ## 유저 레벨\n",
    "        data2['user_rank'].append(soup.find_all('span', {'class' : 'txt_badge'})[j].get_text().strip('레벨'))\n",
    "        ## 유저 후기수\n",
    "        data2['num_response'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[0].get_text()\n",
    "        )\n",
    "        ## 유저 별점 평균\n",
    "        data2['user_star'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[1].get_text()\n",
    "        )\n",
    "        ### 리뷰 작성 시간\n",
    "        data2['time'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find('span',{'class':'time_write'}).get_text()\n",
    "        )\n",
    "        ## 리뷰 내용\n",
    "        data2['content'].append(\n",
    "            soup.find_all('p', {'class':'txt_comment'})[j].get_text().strip('더보기')\n",
    "        )\n",
    "\n",
    "        ## 유저가 평가한 별점 \n",
    "        # 너비를 추출하여 별점 계산 (너비는 별점의 백분율을 나타냄)\n",
    "        style_attribute = soup.find_all('div', {'class':'star_info'})[j].find('span',{'class':'ico_star inner_star'})['style']\n",
    "        width_percent = float(style_attribute.split(':')[1].strip('%;'))\n",
    "        rating_out_of_five = width_percent / 20  # 별점은 100%를 5로 나눈 값\n",
    "        data2['rating'].append(rating_out_of_five)\n",
    "\n",
    "    ## 데이터 프레임으로 만들기\n",
    "    df2 = pd.DataFrame(data2)\n",
    "    df2.to_csv(f'./data2/{mer}.csv',index = False)\n",
    "\n",
    "\n",
    "    # 이미지 데이터를 파일로 저장\n",
    "    with open(f'./image/{mer}1.png', 'wb') as f:\n",
    "        f.write(image_data_decoded)\n",
    "\n",
    "    with open(f'./image/{mer}2.png', 'wb') as f:\n",
    "        f.write(image_data_decoded2)\n",
    "\n",
    "    print(f\"{i+1}번째 데이터 입력 완료, {mer}.csv 저장 완료, {mer}.png 저장 완료\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"./data1/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'url' must be a string\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7956C1522+60802]\n\t(No symbol) [0x00007FF79563AC22]\n\t(No symbol) [0x00007FF7954F7CE4]\n\t(No symbol) [0x00007FF79558AC3E]\n\t(No symbol) [0x00007FF79556AB7A]\n\t(No symbol) [0x00007FF79558A224]\n\t(No symbol) [0x00007FF79556A923]\n\t(No symbol) [0x00007FF795538FEC]\n\t(No symbol) [0x00007FF795539C21]\n\tGetHandleVerifier [0x00007FF7959C413D+3217821]\n\tGetHandleVerifier [0x00007FF795A060D7+3488055]\n\tGetHandleVerifier [0x00007FF7959FF05F+3459263]\n\tGetHandleVerifier [0x00007FF79577B866+823494]\n\t(No symbol) [0x00007FF795645FBF]\n\t(No symbol) [0x00007FF795640EE4]\n\t(No symbol) [0x00007FF795641072]\n\t(No symbol) [0x00007FF7956318C4]\n\tBaseThreadInitThunk [0x00007FF9F2537344+20]\n\tRtlUserThreadStart [0x00007FF9F41E26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_a\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_list)\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m, in \u001b[0;36mscrape_data\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m data2 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_rank\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_response\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_star\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m     12\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m driver\u001b[38;5;241m.\u001b[39mimplicitly_wait(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'url' must be a string\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7956C1522+60802]\n\t(No symbol) [0x00007FF79563AC22]\n\t(No symbol) [0x00007FF7954F7CE4]\n\t(No symbol) [0x00007FF79558AC3E]\n\t(No symbol) [0x00007FF79556AB7A]\n\t(No symbol) [0x00007FF79558A224]\n\t(No symbol) [0x00007FF79556A923]\n\t(No symbol) [0x00007FF795538FEC]\n\t(No symbol) [0x00007FF795539C21]\n\tGetHandleVerifier [0x00007FF7959C413D+3217821]\n\tGetHandleVerifier [0x00007FF795A060D7+3488055]\n\tGetHandleVerifier [0x00007FF7959FF05F+3459263]\n\tGetHandleVerifier [0x00007FF79577B866+823494]\n\t(No symbol) [0x00007FF795645FBF]\n\t(No symbol) [0x00007FF795640EE4]\n\t(No symbol) [0x00007FF795641072]\n\t(No symbol) [0x00007FF7956318C4]\n\tBaseThreadInitThunk [0x00007FF9F2537344+20]\n\tRtlUserThreadStart [0x00007FF9F41E26B1+33]\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "# 함수 정의\n",
    "def scrape_data(url):\n",
    "    data = {'merchant': [], 'category': [], 'address': [], 'star': [], 'starCount': [], 'reviewCount': [], 'oper_time': []}\n",
    "    data2 = {'user_name': [], 'user_rank': [], 'num_response': [], 'user_star': [], 'time': [], 'content': [], 'rating': []}\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    try:\n",
    "        oper_more = driver.find_elements(By.CSS_SELECTOR, 'a[data-logevent=\"main_info,more_timeinfo\"]')\n",
    "        if oper_more:\n",
    "            oper_more[0].click()\n",
    "            time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 후기 더보기 클릭\n",
    "    try:\n",
    "        link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "        while link_more.text == \"후기 더보기\":\n",
    "            link_more.click()\n",
    "            time.sleep(0.3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "    data['merchant'].append(soup.find('h2', {'class': 'tit_location'}).get_text())\n",
    "    data['category'].append(soup.find('span', {'class': 'txt_location'}).get_text().split(':')[1].strip())\n",
    "    data['address'].append(soup.find('span', {'class': 'txt_address'}).get_text().replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "    if len(soup.find_all('span', {'class': 'color_b'})) > 1:\n",
    "        data['star'].append(soup.find_all('span', {'class': 'color_b'})[0].get_text().strip('점'))\n",
    "        data['starCount'].append(soup.find('a', {'class': 'link_evaluation'})['data-cnt'])\n",
    "        data['reviewCount'].append(soup.find_all('span', {'class': 'color_b'})[1].get_text().strip('개'))\n",
    "    else:\n",
    "        data['star'].append('0')\n",
    "        data['starCount'].append('0')\n",
    "        data['reviewCount'].append(soup.find('span', {'class': 'color_b'}).get_text().strip('개'))\n",
    "    if oper_more:\n",
    "        data['oper_time'].append(soup.find_all('ul', {'class': 'list_operation'})[1].get_text().strip())\n",
    "    else:\n",
    "        data['oper_time'].append(soup.find('ul', {'class': 'list_operation'}).get_text().strip().replace(\"\\n\", \"\"))\n",
    "    review_listed = soup.find_all('li', {'data-ismy': 'false'})\n",
    "\n",
    "    for j in range(len(review_listed)):\n",
    "        data2['user_name'].append(soup.find_all('span', {'class': 'txt_username'})[j].get_text())\n",
    "        data2['user_rank'].append(soup.find_all('span', {'class': 'txt_badge'})[j].get_text().strip('레벨'))\n",
    "        data2['num_response'].append(soup.find_all('div', {'class': 'unit_info'})[j].find_all('span', {'class': 'txt_desc'})[0].get_text())\n",
    "        data2['user_star'].append(soup.find_all('div', {'class': 'unit_info'})[j].find_all('span', {'class': 'txt_desc'})[1].get_text())\n",
    "        data2['time'].append(soup.find_all('div', {'class': 'unit_info'})[j].find('span', {'class': 'time_write'}).get_text())\n",
    "        data2['content'].append(soup.find_all('p', {'class': 'txt_comment'})[j].get_text().strip('더보기'))\n",
    "        style_attribute = soup.find_all('div', {'class': 'star_info'})[j].find('span', {'class': 'ico_star inner_star'})['style']\n",
    "        width_percent = float(style_attribute.split(':')[1].strip('%;'))\n",
    "        rating_out_of_five = width_percent / 20\n",
    "        data2['rating'].append(rating_out_of_five)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    df2 = pd.DataFrame(data2)\n",
    "    df2.to_csv(f'./data2/{soup.find(\"h2\", {\"class\": \"tit_location\"}).get_text()}.csv', index=False)\n",
    "\n",
    "    print(f\"{url} 데이터 입력 완료, {soup.find('h2', {'class':'tit_location'}).get_text()}.csv 저장 완료\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# 메인 코드\n",
    "url_a = [list_url]  # 매장 URL 리스트\n",
    "\n",
    "data_list = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for result in executor.map(scrape_data, url_a):\n",
    "        data_list.append(result)\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.to_csv(\"./data1/data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
