{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import concurrent.futures\n",
    "\n",
    "def scrape_data(url):\n",
    "    data = {\n",
    "        'merchant' : [],\n",
    "        'category' : [],\n",
    "        'star' : [],\n",
    "        'address' : [],\n",
    "        'oper_time' : [],\n",
    "        'starCount' : [],\n",
    "        'reviewCount' : []\n",
    "    }\n",
    "    data2 = {\n",
    "        'user_name' : [],\n",
    "        'user_rank' : [],\n",
    "        'num_response' : [],\n",
    "        'user_star' : [], \n",
    "        'time' : [],\n",
    "        'rating' : [],\n",
    "        'content' : []\n",
    "    }\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 영업시간 더 보기 클릭\n",
    "    try:\n",
    "        oper_more = driver.find_elements(By.CSS_SELECTOR, 'a[data-logevent = \"main_info,more_timeinfo\"]')\n",
    "        oper_more[0].click()\n",
    "        time.sleep(2)  \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 후기 더보기 클릭\n",
    "    try:\n",
    "        link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "        while link_more.text == \"후기 더보기\":\n",
    "            link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "            if link_more.text != \"후기 접기\":\n",
    "                link_more.click()\n",
    "                time.sleep(0.3)\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(0.1)\n",
    "  \n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "    test_image = driver.execute_script(\"return document.querySelectorAll('canvas')[1].toDataURL();\")\n",
    "    image_data = test_image.split(',')[1]\n",
    "    image_data_decoded = base64.b64decode(image_data)\n",
    "\n",
    "    test_image2 = driver.execute_script(\"return document.querySelectorAll('canvas')[2].toDataURL();\")\n",
    "    image_data2 = test_image2.split(',')[1]\n",
    "    image_data_decoded2 = base64.b64decode(image_data2)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    mer = soup.find('h2', {'class':'tit_location'}).get_text()\n",
    "    data['merchant'].append(mer)\n",
    "    data['category'].append(soup.find('span',{'class':'txt_location'}).get_text().split(':')[1].strip())\n",
    "    data['address'].append(soup.find('span', {'class': 'txt_address'}).get_text().replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "    if len(soup.find_all('span',{'class':'color_b'})) > 1:\n",
    "        data['star'].append(soup.find_all('span', {'class':'color_b'})[0].get_text().strip('점'))\n",
    "        data['starCount'].append(soup.find('a', {'class': 'link_evaluation'})['data-cnt'])\n",
    "        data['reviewCount'].append(soup.find_all('span', {'class':'color_b'})[1].get_text().strip('개'))\n",
    "    else:\n",
    "        data['star'].append('0')\n",
    "        data['starCount'].append('0')\n",
    "        data['reviewCount'].append(soup.find('span', {'class':'color_b'}).get_text().strip('개'))\n",
    "\n",
    "    if oper_more:    \n",
    "        data['oper_time'].append(soup.find_all('ul', {'class':'list_operation'})[1].get_text().strip())\n",
    "    else:\n",
    "        data['oper_time'].append(soup.find('ul', {'class':'list_operation'}).get_text().strip().replace(\"\\n\", \"\"))\n",
    "\n",
    "    reveiw_listed = soup.find_all('li', {'data-ismy':'false'})\n",
    "\n",
    "    for j in range(len(reveiw_listed)):\n",
    "        data2['user_name'].append(soup.find_all('span',{'class':'txt_username'})[j].get_text())\n",
    "        data2['user_rank'].append(soup.find_all('span', {'class' : 'txt_badge'})[j].get_text().strip('레벨'))\n",
    "        data2['num_response'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[0].get_text()\n",
    "        )\n",
    "        data2['user_star'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[1].get_text()\n",
    "        )\n",
    "        data2['time'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find('span',{'class':'time_write'}).get_text()\n",
    "        )\n",
    "        data2['content'].append(\n",
    "            soup.find_all('p', {'class':'txt_comment'})[j].get_text().strip('더보기')\n",
    "        )\n",
    "\n",
    "        style_attribute = soup.find_all('div', {'class':'star_info'})[j].find('span',{'class':'ico_star inner_star'})['style']\n",
    "        width_percent = float(style_attribute.split(':')[1].strip('%;'))\n",
    "        rating_out_of_five = width_percent / 20  \n",
    "        data2['rating'].append(rating_out_of_five)\n",
    "\n",
    "    df2 = pd.DataFrame(data2)\n",
    "    df2.to_csv(f'./data2/{mer}.csv', index=False)\n",
    "\n",
    "    with open(f'./image/{mer}1.png', 'wb') as f:\n",
    "        f.write(image_data_decoded)\n",
    "\n",
    "    with open(f'./image/{mer}2.png', 'wb') as f:\n",
    "        f.write(image_data_decoded2)\n",
    "\n",
    "    print(f\"{mer}.csv 및 이미지 저장 완료\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://map.kakao.com/')\n",
    "    time.sleep(2)\n",
    "\n",
    "    searchbox = driver.find_element(By.ID, 'search.keyword.query')\n",
    "    searchbox.send_keys('홍대 맛집'+ Keys.ENTER)\n",
    "    time.sleep(3)\n",
    "\n",
    "    list_url = []\n",
    "\n",
    "    driver.find_element(By.ID, 'info.search.place.more').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.ID, 'info.search.page.no1').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    for count in range(1):\n",
    "        for inx in range(2, 6):\n",
    "            moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "            for i in range(len(moreview_element)):\n",
    "                list_url.append(moreview_element[i].get_attribute('href'))\n",
    "            driver.find_element(By.ID, f'info.search.page.no{inx}').click()\n",
    "            if inx == 5:\n",
    "                moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "                for i in range(len(moreview_element)):\n",
    "                    list_url.append(moreview_element[i].get_attribute('href'))\n",
    "            time.sleep(2)\n",
    "        driver.find_element(By.ID ,'info.search.page.next').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    data_list = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(scrape_data, list_url)\n",
    "        for result in results:\n",
    "            data_list.append(result)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.to_csv(\"./data1/data.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import concurrent.futures\n",
    "\n",
    "def scrape_data(url):\n",
    "    data = {\n",
    "        'merchant' : [],\n",
    "        'category' : [],\n",
    "        'star' : [],\n",
    "        'address' : [],\n",
    "        'oper_time' : [],\n",
    "        'starCount' : [],\n",
    "        'reviewCount' : []\n",
    "    }\n",
    "    data2 = {\n",
    "        'user_name' : [],\n",
    "        'user_rank' : [],\n",
    "        'num_response' : [],\n",
    "        'user_star' : [], \n",
    "        'time' : [],\n",
    "        'rating' : [],\n",
    "        'content' : []\n",
    "    }\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    # 영업시간 더 보기 클릭\n",
    "    try:\n",
    "        oper_more = driver.find_elements(By.CSS_SELECTOR, 'a[data-logevent = \"main_info,more_timeinfo\"]')\n",
    "        oper_more[0].click()\n",
    "        time.sleep(2)  \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 후기 더보기 클릭\n",
    "    try:\n",
    "        link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "        while link_more.text == \"후기 더보기\":\n",
    "            link_more = driver.find_element(By.CLASS_NAME, 'txt_more')\n",
    "            if link_more.text != \"후기 접기\":\n",
    "                link_more.click()\n",
    "                time.sleep(0.3)\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(0.1)\n",
    "  \n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "    test_image = driver.execute_script(\"return document.querySelectorAll('canvas')[1].toDataURL();\")\n",
    "    image_data = test_image.split(',')[1]\n",
    "    image_data_decoded = base64.b64decode(image_data)\n",
    "\n",
    "    test_image2 = driver.execute_script(\"return document.querySelectorAll('canvas')[2].toDataURL();\")\n",
    "    image_data2 = test_image2.split(',')[1]\n",
    "    image_data_decoded2 = base64.b64decode(image_data2)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    mer = soup.find('h2', {'class':'tit_location'}).get_text()\n",
    "    data['merchant'].append(mer)\n",
    "    data['category'].append(soup.find('span',{'class':'txt_location'}).get_text().split(':')[1].strip())\n",
    "    data['address'].append(soup.find('span', {'class': 'txt_address'}).get_text().replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "    if len(soup.find_all('span',{'class':'color_b'})) > 1:\n",
    "        data['star'].append(soup.find_all('span', {'class':'color_b'})[0].get_text().strip('점'))\n",
    "        data['starCount'].append(soup.find('a', {'class': 'link_evaluation'})['data-cnt'])\n",
    "        data['reviewCount'].append(soup.find_all('span', {'class':'color_b'})[1].get_text().strip('개'))\n",
    "    else:\n",
    "        data['star'].append('0')\n",
    "        data['starCount'].append('0')\n",
    "        data['reviewCount'].append(soup.find('span', {'class':'color_b'}).get_text().strip('개'))\n",
    "\n",
    "    if oper_more:    \n",
    "        data['oper_time'].append(soup.find_all('ul', {'class':'list_operation'})[1].get_text().strip())\n",
    "    else:\n",
    "        data['oper_time'].append(soup.find('ul', {'class':'list_operation'}).get_text().strip().replace(\"\\n\", \"\"))\n",
    "\n",
    "    reveiw_listed = soup.find_all('li', {'data-ismy':'false'})\n",
    "\n",
    "    for j in range(len(reveiw_listed)):\n",
    "        data2['user_name'].append(soup.find_all('span',{'class':'txt_username'})[j].get_text())\n",
    "        data2['user_rank'].append(soup.find_all('span', {'class' : 'txt_badge'})[j].get_text().strip('레벨'))\n",
    "        data2['num_response'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[0].get_text()\n",
    "        )\n",
    "        data2['user_star'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find_all('span',{'class':'txt_desc'})[1].get_text()\n",
    "        )\n",
    "        data2['time'].append(\n",
    "            soup.find_all('div',{'class':'unit_info'})[j].find('span',{'class':'time_write'}).get_text()\n",
    "        )\n",
    "        data2['content'].append(\n",
    "            soup.find_all('p', {'class':'txt_comment'})[j].get_text().strip('더보기')\n",
    "        )\n",
    "\n",
    "        style_attribute = soup.find_all('div', {'class':'star_info'})[j].find('span',{'class':'ico_star inner_star'})['style']\n",
    "        width_percent = float(style_attribute.split(':')[1].strip('%;'))\n",
    "        rating_out_of_five = width_percent / 20  \n",
    "        data2['rating'].append(rating_out_of_five)\n",
    "\n",
    "    df2 = pd.DataFrame(data2)\n",
    "    df2.to_csv(f'./data2/{mer}.csv', index=False)\n",
    "\n",
    "    with open(f'./image/{mer}1.png', 'wb') as f:\n",
    "        f.write(image_data_decoded)\n",
    "\n",
    "    with open(f'./image/{mer}2.png', 'wb') as f:\n",
    "        f.write(image_data_decoded2)\n",
    "\n",
    "    print(f\"{mer}.csv 및 이미지 저장 완료\")\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "또보겠지떡볶이집 깐따삐아점.csv 및 이미지 저장 완료\n",
      "비스트로주라.csv 및 이미지 저장 완료\n"
     ]
    },
    {
     "ename": "JavascriptException",
     "evalue": "Message: javascript error: Cannot read properties of undefined (reading 'toDataURL')\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7956C1522+60802]\n\t(No symbol) [0x00007FF79563AC22]\n\t(No symbol) [0x00007FF7954F7CE4]\n\t(No symbol) [0x00007FF7954FDE26]\n\t(No symbol) [0x00007FF7955004F6]\n\t(No symbol) [0x00007FF79558AEC3]\n\t(No symbol) [0x00007FF79556AB7A]\n\t(No symbol) [0x00007FF79558A224]\n\t(No symbol) [0x00007FF79556A923]\n\t(No symbol) [0x00007FF795538FEC]\n\t(No symbol) [0x00007FF795539C21]\n\tGetHandleVerifier [0x00007FF7959C413D+3217821]\n\tGetHandleVerifier [0x00007FF795A060D7+3488055]\n\tGetHandleVerifier [0x00007FF7959FF05F+3459263]\n\tGetHandleVerifier [0x00007FF79577B866+823494]\n\t(No symbol) [0x00007FF795645FBF]\n\t(No symbol) [0x00007FF795640EE4]\n\t(No symbol) [0x00007FF795641072]\n\t(No symbol) [0x00007FF7956318C4]\n\tBaseThreadInitThunk [0x00007FF9F2537344+20]\n\tRtlUserThreadStart [0x00007FF9F41E26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavascriptException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data1/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 35\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     34\u001b[0m     results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(scrape_data, list_url)\n\u001b[1;32m---> 35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_list)\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mscrape_data\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     56\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     58\u001b[0m soup \u001b[38;5;241m=\u001b[39m bs(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m test_image \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.querySelectorAll(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcanvas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)[1].toDataURL();\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m image_data \u001b[38;5;241m=\u001b[39m test_image\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     62\u001b[0m image_data_decoded \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(image_data)\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:407\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    404\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Jws\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mJavascriptException\u001b[0m: Message: javascript error: Cannot read properties of undefined (reading 'toDataURL')\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7956C1522+60802]\n\t(No symbol) [0x00007FF79563AC22]\n\t(No symbol) [0x00007FF7954F7CE4]\n\t(No symbol) [0x00007FF7954FDE26]\n\t(No symbol) [0x00007FF7955004F6]\n\t(No symbol) [0x00007FF79558AEC3]\n\t(No symbol) [0x00007FF79556AB7A]\n\t(No symbol) [0x00007FF79558A224]\n\t(No symbol) [0x00007FF79556A923]\n\t(No symbol) [0x00007FF795538FEC]\n\t(No symbol) [0x00007FF795539C21]\n\tGetHandleVerifier [0x00007FF7959C413D+3217821]\n\tGetHandleVerifier [0x00007FF795A060D7+3488055]\n\tGetHandleVerifier [0x00007FF7959FF05F+3459263]\n\tGetHandleVerifier [0x00007FF79577B866+823494]\n\t(No symbol) [0x00007FF795645FBF]\n\t(No symbol) [0x00007FF795640EE4]\n\t(No symbol) [0x00007FF795641072]\n\t(No symbol) [0x00007FF7956318C4]\n\tBaseThreadInitThunk [0x00007FF9F2537344+20]\n\tRtlUserThreadStart [0x00007FF9F41E26B1+33]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://map.kakao.com/')\n",
    "    time.sleep(2)\n",
    "\n",
    "    searchbox = driver.find_element(By.ID, 'search.keyword.query')\n",
    "    searchbox.send_keys('홍대 맛집'+ Keys.ENTER)\n",
    "    time.sleep(3)\n",
    "\n",
    "    list_url = []\n",
    "\n",
    "    driver.find_element(By.ID, 'info.search.place.more').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.ID, 'info.search.page.no1').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    for count in range(1):\n",
    "        for inx in range(2, 3):\n",
    "            moreview_element = driver.find_elements(By.CSS_SELECTOR, 'a[data-id=\"moreview\"]')\n",
    "            for i in range(9,12):\n",
    "                list_url.append(moreview_element[i].get_attribute('href'))\n",
    "            driver.find_element(By.ID, f'info.search.page.no{inx}').click()\n",
    "\n",
    "            time.sleep(2)\n",
    "        driver.find_element(By.ID ,'info.search.page.next').click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(len(list_url))\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    data_list = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(scrape_data, list_url)\n",
    "        for result in results:\n",
    "            data_list.append(result)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.to_csv(\"./data1/data.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= pd.read_csv('./data1/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>star</th>\n",
       "      <th>address</th>\n",
       "      <th>oper_time</th>\n",
       "      <th>starCount</th>\n",
       "      <th>reviewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['피오니 홍대점']</td>\n",
       "      <td>['카페']</td>\n",
       "      <td>['3.8']</td>\n",
       "      <td>['서울마포구독막로7길511층(우)04043']</td>\n",
       "      <td>['매일 12:00 ~ 21:00\\n\\n매일 라스트오더 ~ 20:30']</td>\n",
       "      <td>['274']</td>\n",
       "      <td>['642']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['943킹스크로스']</td>\n",
       "      <td>['테마카페']</td>\n",
       "      <td>['4.1']</td>\n",
       "      <td>['서울마포구양화로16길24지하1층,1~4층(우)04039']</td>\n",
       "      <td>['월~목 11:30 ~ 21:30\\n\\n금~일 10:00 ~ 21:30']</td>\n",
       "      <td>['360']</td>\n",
       "      <td>['191']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['카미야']</td>\n",
       "      <td>['돈까스,우동']</td>\n",
       "      <td>['4.2']</td>\n",
       "      <td>['서울마포구와우산로21길28-6지하1층(우)04040']</td>\n",
       "      <td>['매일 11:00 ~ 21:30\\n\\n매일 라스트오더 ~ 21:00']</td>\n",
       "      <td>['191']</td>\n",
       "      <td>['426']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['우와 홍대본점']</td>\n",
       "      <td>['일식']</td>\n",
       "      <td>['3.4']</td>\n",
       "      <td>['서울마포구와우산로21길21-162층202호(우)04041']</td>\n",
       "      <td>['매일 12:00 ~ 22:00월~금 휴게시간 14:30 ~ 17:00']</td>\n",
       "      <td>['168']</td>\n",
       "      <td>['624']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['칸다소바 홍대점']</td>\n",
       "      <td>['일본식라면']</td>\n",
       "      <td>['4.3']</td>\n",
       "      <td>['서울마포구와우산로51-61층(우)04049']</td>\n",
       "      <td>['매일 10:30 ~ 21:30\\n\\n월~토 휴게시간 16:00 ~ 17:00\\n...</td>\n",
       "      <td>['279']</td>\n",
       "      <td>['439']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant    category     star                              address  \\\n",
       "0   ['피오니 홍대점']      ['카페']  ['3.8']           ['서울마포구독막로7길511층(우)04043']   \n",
       "1  ['943킹스크로스']    ['테마카페']  ['4.1']   ['서울마포구양화로16길24지하1층,1~4층(우)04039']   \n",
       "2       ['카미야']  ['돈까스,우동']  ['4.2']     ['서울마포구와우산로21길28-6지하1층(우)04040']   \n",
       "3   ['우와 홍대본점']      ['일식']  ['3.4']  ['서울마포구와우산로21길21-162층202호(우)04041']   \n",
       "4  ['칸다소바 홍대점']   ['일본식라면']  ['4.3']          ['서울마포구와우산로51-61층(우)04049']   \n",
       "\n",
       "                                           oper_time starCount reviewCount  \n",
       "0           ['매일 12:00 ~ 21:00\\n\\n매일 라스트오더 ~ 20:30']   ['274']     ['642']  \n",
       "1         ['월~목 11:30 ~ 21:30\\n\\n금~일 10:00 ~ 21:30']   ['360']     ['191']  \n",
       "2           ['매일 11:00 ~ 21:30\\n\\n매일 라스트오더 ~ 21:00']   ['191']     ['426']  \n",
       "3         ['매일 12:00 ~ 22:00월~금 휴게시간 14:30 ~ 17:00']   ['168']     ['624']  \n",
       "4  ['매일 10:30 ~ 21:30\\n\\n월~토 휴게시간 16:00 ~ 17:00\\n...   ['279']     ['439']  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('./data2/카미야.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_rank</th>\n",
       "      <th>num_response</th>\n",
       "      <th>user_star</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김나영</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024.04.11.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내돈내산 솔직리뷰</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2024.04.09.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>돈까스 맛은 제 동네와 비슷한데 여긴 레몬즙이 있어서 뿌려먹으니 안물리고 맛있었어요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>냐옹</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2024.04.08.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ㅇㅇ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.04.08.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>웨이팅하고 오꼬노미야끼동 먹었어요. 맛있게 먹고 있었는데 나이 좀 있으신 여자분 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>마포구 쩝쩝박사</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2024.04.04.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>엄청 뛰어난 맛은 아닌데 가격이 좋아요 요즘 기본 만오천 넘는데 치즈카츠 만원임</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>디카페인</td>\n",
       "      <td>31</td>\n",
       "      <td>134</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2019.02.11.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>냉모밀 짱짱 추천. 메뉴 전부 맛있지만 전체적으로 짠 편임.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>.</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2019.01.20.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>치즈카츠랑 새우튀김을 정말 좋아하는데 아주 만족스러웠어요 그리고 크로켓을 추가로 주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>TBO</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2018.12.10.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>[CHAN]</td>\n",
       "      <td>33</td>\n",
       "      <td>277</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2018.09.25.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>샐러드 5우동.    5히레.    2.5로스.    3.0서비스 굿기름이 별로인듯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>MJay Ko 고 민정</td>\n",
       "      <td>89</td>\n",
       "      <td>8,538</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2016.05.16.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>로스히레 or 에비로스가츠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_name  user_rank num_response  user_star         time  rating  \\\n",
       "0             김나영          8           24        5.0  2024.04.11.     5.0   \n",
       "1       내돈내산 솔직리뷰         26           63        3.5  2024.04.09.     3.0   \n",
       "2              냐옹         18           88        3.8  2024.04.08.     5.0   \n",
       "3              ㅇㅇ          3            1        2.0  2024.04.08.     2.0   \n",
       "4        마포구 쩝쩝박사         33           89        3.3  2024.04.04.     4.0   \n",
       "..            ...        ...          ...        ...          ...     ...   \n",
       "186          디카페인         31          134        4.1  2019.02.11.     4.0   \n",
       "187             .         10            9        3.3  2019.01.20.     5.0   \n",
       "188           TBO          3           15        2.5  2018.12.10.     4.0   \n",
       "189        [CHAN]         33          277        3.4  2018.09.25.     3.0   \n",
       "190  MJay Ko 고 민정         89        8,538        3.3  2016.05.16.     3.0   \n",
       "\n",
       "                                               content  \n",
       "0                                                  NaN  \n",
       "1    돈까스 맛은 제 동네와 비슷한데 여긴 레몬즙이 있어서 뿌려먹으니 안물리고 맛있었어요...  \n",
       "2                                                  NaN  \n",
       "3    웨이팅하고 오꼬노미야끼동 먹었어요. 맛있게 먹고 있었는데 나이 좀 있으신 여자분 오...  \n",
       "4         엄청 뛰어난 맛은 아닌데 가격이 좋아요 요즘 기본 만오천 넘는데 치즈카츠 만원임  \n",
       "..                                                 ...  \n",
       "186                  냉모밀 짱짱 추천. 메뉴 전부 맛있지만 전체적으로 짠 편임.  \n",
       "187  치즈카츠랑 새우튀김을 정말 좋아하는데 아주 만족스러웠어요 그리고 크로켓을 추가로 주...  \n",
       "188                                                NaN  \n",
       "189  샐러드 5우동.    5히레.    2.5로스.    3.0서비스 굿기름이 별로인듯...  \n",
       "190                                     로스히레 or 에비로스가츠  \n",
       "\n",
       "[191 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
